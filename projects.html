<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Projects · Tomás Sánchez Villaluenga</title>
<meta name="description" content="Selected projects in AI, event-based vision, ROS2 and embedded systems.">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="stylesheet" href="/assets/css/style.css">
<meta property="og:title" content="Projects · Tomás Sánchez Villaluenga">
<meta property="og:description" content="Selected projects in AI, event-based vision, ROS2 and embedded systems.">
<meta property="og:type" content="website">
<meta property="og:image" content="https://">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Person",
  "name": "Tom\u00e1s S\u00e1nchez Villaluenga",
  "url": "https://example.github.io",
  "email": "mailto:tsvillaluenga@gmail.com",
  "jobTitle": "AI / Robotics Engineer",
  "sameAs": [
    "https://www.linkedin.com/in/tomas-sanchez-villaluenga-9b2b33232/"
  ]
}
</script>
</head>
<body>
<nav class="nav"><div class="container inner">
  <div class="brand"><a href="/">Tomás Sánchez Villaluenga</a></div>
  <div class="menu">
    <a href="/">About</a>
    <a href="/publications.html">Publications</a>
    <a href="/projects.html">Projects</a>
    <a href="/cv.html">CV</a>
    <a href="/contact.html">Contact</a>
  </div>
</div></nav>
<div class="container">

<h2>Selected Projects</h2>
<div class="grid cols-2">
  <div class="card">
    <h3>Event‑Based Logistics Model, Dataset & 3D NeRF</h3>
    <p class="meta">TU Dortmund · FLW Chair</p>
    <ul class="clean">
      <li><strong>Self-supervised learning</strong> model creation for <strong>3D prediction</strong> of logistic objects.</li>
      <li>Automated preprocessing, segmentation, and labeling of event‑based data.</li>
      <li><strong>LLMs</strong> analysis for segmentation processes.</li>
      <li>Fine tune for multiple logistic objects.</li>
      <li>Built a logistics dataset and <strong>NeRF‑based 3D</strong> assets to improve training.</li>
      <li>Open‑source algorithms replacing physical position markers safely.</li>
      <p>
      <a href="https://oa.upm.es/89418/" target="_blank" rel="noopener">View project</a>
    </p>
<p><a href="https://vimeo.com/1088729957" target="_blank" rel="noopener">View video</a></p>
<p><a href="https://github.com/tsvillaluenga/LEOD_FLW" target="_blank" rel="noopener">View repository</a></p>
    </ul>
  </div>
<div class="card">
  <h3>Patent: Wearable Impact Detection System</h3>
  <p class="meta">Based on Bachelor’s Thesis · Universidad Politécnica de Madrid (UPM)</p>
  <ul class="clean">
    <li>Low power system.</li>
    <li>Designed a portable system embedded in wearable hardware to detect impacts and monitor the user's status via capacitive fabric sensors.</li>
    <li>Developed both <strong>hardware prototype and system architecture</strong>, culminating in a patent filed and published by UPM.</li>
    <p>
      <a href="https://www.upm.es/recursosidi/offers-resources/patentes/dispositivo-portable-y-comunicado-de-deteccion-de-impactos-y-monitorizacion-del-estado-del-usuario-que-lo-porta-y-sistema-que-lo-comprende/" target="_blank" rel="noopener">View patent</a>
    </p>
  </ul>
</div>

<div class="card">
  <h3>Guidance and Navigation of a Cleaning Robot</h3>
  <p class="meta">Master’s Project · Universidad Politécnica de Madrid (UPM)</p>
  <ul class="clean">
    <li>Designed and implemented algorithms for navigation and cleaning in a simulated apartment environment using Apolo.</li>
    <li>Developed modules for localization (<strong>Extended Kalman Filter, EKF</strong>), path planning (<strong>Voronoi + A*</strong>), and reactive obstacle avoidance.</li>
    <li>Integrated user interface to select rooms for cleaning and implemented systematic zig-zag coverage algorithms.</li>
    <p>
      <a href="/docs/Cleaning_Robot.pdf" target="_blank" rel="noopener">
        Download project report (PDF)
      </a>
    </p>
  </ul>
</div>

<div class="card">
  <h3>Automated Tetris with Artificial Intelligence</h3>
  <p class="meta">Master’s Project · Universidad Politécnica de Madrid (UPM)</p>
  <ul class="clean">
    <li>Developed a C++ implementation of Tetris enhanced with AI decision-making capabilities.</li>
    <li>Implemented <strong>multiple training approaches</strong>: competition-based learning, gradient optimization, and a genetic algorithm.</li>
    <li>Achieved a <strong>maximum score of 1.8M points</strong> with predictive strategies, surpassing typical human play.</li>
    <p>
      <a href="/docs/Automated_Tetris.pdf" target="_blank" rel="noopener">
        Download project report (PDF)
      </a>
    </p>
  </ul>
</div>

  <div class="card">
    <h3>Airbus SMART MRTT · Critical Embedded Systems</h3>
    <p class="meta">Airbus Defence and Space</p>
    <ul class="clean">
      <li>Advanced training in RTOS, FPGA, and microelectronics.</li>
      <li>Verification & certification of <strong>DAL‑A risk</strong> requirements (Internal Processing).</li>
    </ul>
  </div>

  <div class="card">
    <h3>IoT Wearables with TENGs</h3>
    <p class="meta">IMDEA Materials</p>
    <ul class="clean">
      <li><strong>New aproach</strong> of a Fire‑detection and alert systems using novel materials.</li>
      <li>Smart wearables and a full <strong>TENG</strong>‑based intelligent vest.</li>
      <li>IoT devices from new materials proof of concept.</li>
<p><a href="https://www.frontiersin.org/journals/detector-science-and-technology/articles/10.3389/fdest.2025.1484647/full" target="_blank" rel="noopener">View publication</a></p>
    </ul>
  </div>

  <div class="card">
    <h3>ROS2 Node Optimization in Aerostack2</h3>
    <p class="meta">CVAR ‑ Universidad Politécnica de Madrid (UPM)</p>
    <ul class="clean">
      <li>Aerostack2 firmware enhancing: Analyzing standard, composable and lifecycle nodes.</li>
      <li>Recommended mission nodes migration to composable for lower resource usage.</li>
    </ul>
  </div>






<!-- Deep Unsupervised Learning & Computer Vision Projects -->

<!-- Integrative Project -->
<div class="card">
  <h3>Multimodal Generative AI Framework</h3>
  <p class="meta">Final Course Project · University of Oxford </p>
  <ul class="clean">
    <li><strong>Grade: A+</strong></li>
    <li>Proposed a unified framework integrating <strong>Autoencoders</strong>, <strong>VAEs</strong>, <strong>GANs</strong>, <strong>Diffusion Models</strong> and <strong>CLIP</strong>.</li>
    <li>Combined inpainting, conditional generation, style transfer, text-to-image synthesis and multimodal search into a single pipeline.</li>
    <li>Outlined potential applications for creative industries, digital content generation and visual search engines.</li>
  </ul>
  <p><a href="https://drive.google.com/drive/folders/1tApsjdJd_rrmv7rFlb4_QUU3pajIASuf?usp=sharing" target="_blank" rel="noopener">Project summary</a></p>
</div>

<div class="card">
  <h3>Multimodal Visual Intelligence Platform</h3>
  <p class="meta">Final Course Project · University of Oxford </p>
  <ul class="clean">
    <li><strong>Grade: A+</strong></li>
    <li>Unified <strong>detection</strong> (Faster R-CNN), <strong>classification</strong> (ViT + Swin), <strong>image translation</strong> (Pix2Pix, CycleGAN), <strong>video analysis</strong>, and <strong>vision-language retrieval</strong> (CLIP) in one framework.</li>
    <li>Developed a shared embedding space for multimodal queries (<strong>text → image, image → image, video snippets</strong>).</li>
    <li>Proposed use-cases in biomedical analysis, creative industries, and multimedia search engines.</li>
  </ul>
  <p><a href="https://drive.google.com/drive/folders/1tApsjdJd_rrmv7rFlb4_QUU3pajIASuf?usp=sharing" target="_blank" rel="noopener">Project summary</a></p>
</div>





<!-- AI-Driven Automations -->
<div class="card">
  <h3>AI-Driven Outreach Agent for Industrial PhD & Hiring</h3>
  <p class="meta">Independent Project</p>
  <ul class="clean">
    <li>Built an end-to-end outreach pipeline using <strong>AI agents</strong> and <strong>LLMs</strong> to match companies with user-defined filters (sector, location, visa, research fit).</li>
    <li>Automated <strong>corporate email discovery</strong> and <strong>personalized email generation</strong> (intent-aware prompts: Industrial PhD, visas, timelines, openings).</li>
    <li>Implemented multi-step reasoning: company profiling → contact extraction → message planning → LLM-crafted outreach with tone and goal control.</li>
    <li>Orchestrated retries/guardrails, rate-limits, and logging for safe and consistent delivery.</li>
  </ul>
</div>

<div class="card">
  <h3>Autonomous Job Intelligence Pipeline (LinkedIn + LLM Agents)</h3>
  <p class="meta">Independent Project</p>
  <ul class="clean">
    <li>Created a <strong>scraping & enrichment workflow</strong> that collects roles from LinkedIn by filters and builds a <strong>company & role dossier</strong> (tech stack, research lines, visa notes).</li>
    <li>Used a customized LLM to obtain a relevance index to score each offer (skills match, seniority, research fit, location constraints) and prioritize actions.</li>
    <li>Generated a concise  report per job (pros/cons, risks, next steps) and sent automated email digests with direct apply links.</li>
    <li>Added scheduling, de-duplication, and alerting; supports continuous monitoring and incremental updates.</li>
  </ul>
</div>

<div class="card">
  <h3>Business Automations with AI Agents</h3>
  <p class="meta">Independent Project</p>
  <ul class="clean">
    <li>Designed reusable <strong>automation frameworks</strong> that integrate <strong>LLMs</strong> with multi-step <strong>AI agents</strong> for business operations.</li>
    <li>Focused on improving customer interaction, reducing manual workload, and enabling businesses to leverage AI-driven personalization.</li>
    <li>Scalable design using orchestration tools, APIs, and custom LLM pipelines adapted to each business domain.</li>
  </ul>
</div>


<!-- Deep Unsupervised Learning & Computer Vision Projects -->
<!--
<div class="card">
  <h3>Vision Transformers for Biomedical Image Analysis</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Combined <strong>ViT</strong> and Swin architectures for high-resolution <strong>cell classification</strong>.</li>
    <li>Implemented sliding-window inference for large biomedical images.</li>
    <li>Delivered state-of-the-art classification accuracy in challenging domains.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/10t8Wa-pF96SzmQI_ea0nC_Pi9_-7vD37/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

<div class="card">
  <h3>Vision-Language Models (VLM): CLIP from Scratch</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Implemented <strong>CLIP</strong> architecture from scratch with <strong>contrastive learning</strong>.</li>
    <li>Trained joint <strong>embeddings for images and natural language prompts</strong>.</li>
    <li>Evaluated zero-shot classification and custom prompt engineering.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1aCEhcy6jPqSgWTKW3ey8i1pRKQNgB4BG/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

<div class="card">
  <h3>Image Search Engine with CLIP</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Built a multimodal search engine using <strong>CLIP</strong> embeddings.</li>
    <li>Enabled <strong>text-to-image</strong> and <strong>image-to-image</strong> retrieval on Tiny-ImageNet.</li>
    <li>Delivered an effective zero-shot classification and retrieval system.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1JxhERbOg8eZoQyMb0ok_3EC4heTFpVd5/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

<div class="card">
  <h3>Video Classification via Fine-Tuned Deep Networks</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Fine-tuned pretrained architectures for video sequence classification.</li>
    <li>Designed preprocessing pipelines for temporal action recognition.</li>
    <li>Improved classification accuracy on benchmark datasets.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1QyIvthFMRS3xMH0hEe-thjH2d4_RmYVm/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

<div class="card">
  <h3>Unpaired Image Translation with CycleGAN</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Applied <strong>CycleGAN</strong> for domain translation without paired data.</li>
    <li>Used cycle-consistency loss for stable training.</li>
    <li>Achieved style transfer across domains such as selfies ↔ anime.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1vXj3mYYzVc5J_tnIjDlxahjuN2msSHo7/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>


<div class="card">
  <h3>Image Translation with Pix2Pix</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Trained a Pix2Pix <strong>GAN</strong> with U-Net generator and PatchGAN discriminator.</li>
    <li>Enabled paired image translation (e.g., sketch → realistic photo).</li>
    <li>Applied to creative image-to-image transformation tasks.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1VlJsWT6Q7GYGvAks-cRFt0WwkVxLSQHG/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

<div class="card">
  <h3>Advanced Image Classification with CNNs</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Built and trained <strong>CNNs</strong> with Inception bottlenecks for image classification.</li>
    <li>Compared optimizers, scheduling strategies, and regularization methods.</li>
    <li>Achieved strong performance improvements through architectural tuning.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/19dIW_UilL2Px7ese_wg3kSUvfpBwFjEX/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

<div class="card">
  <h3>Object Detection with Faster R-CNN</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Implemented Faster R-CNN for <strong>vehicle detection</strong>.</li>
    <li>Designed a custom dataset pipeline with <strong>PyTorch</strong>.</li>
    <li>Delivered accurate bounding-box predictions for real-world detection tasks.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1XEqk-Z5s8RFXToG4FubYarqoF8hW_4lh/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

<div class="card">
  <h3>Fine-tuning Stable Diffusion for Domain-Specific Generation</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li><strong>Fine-tuned</strong> a Stable Diffusion pipeline (VAE + UNet + text encoder) on a custom dataset.</li>
    <li>Generated high-quality domain-specific images (e.g., Naruto-style) from text prompts.</li>
    <li>Optimized large-scale diffusion models under GPU constraints.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1v4xUsnK-yMzNTt0Y_5NSLshI_mYbjw4G/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

<div class="card">
  <h3>Conditional VAEs for Controlled Generation</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Built a <strong>conditional VAE</strong> to generate images guided by labels.</li>
    <li>Explored latent space manipulation for class-specific synthesis.</li>
    <li>Demonstrated controllable and diverse outputs across datasets.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1JCo8_oAzqzkWohGF9wpFN4WVKbQPKNKj/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>


<div class="card">
  <h3>Image Inpainting with Autoencoders</h3>
  <p class="meta">University of Oxford · Lady Margaret Hall</p>
  <ul class="clean">
    <li>Designed and implemented a convolutional autoencoder for intelligent image completion.</li>
    <li>Developed customized pipelines to reconstruct missing regions in images.</li>
    <li>Achieved robust inpainting results with strong generalization.</li>
  </ul>
  <p><a href="https://drive.google.com/file/d/1oNTxFmoXfnIR8eSvG4fYSyqHaXahUcgi/view?usp=sharing" target="_blank" rel="noopener">View project</a></p>
</div>

-->









</div>
<footer class="footer">
  <div class="container">
    © Tomás Sánchez Villaluenga · Built with GitHub Pages · <a href="https://github.com">Source</a>
  </div>
</footer>
</body>
</html>
